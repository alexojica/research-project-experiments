{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T14:59:27.830805Z",
     "start_time": "2024-05-03T14:59:22.541684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from src.plots import plot_vae_training_result, plot_image, plot_image_label_two\n",
    "from src.vae.mnist_vae import VaeAutoencoder\n",
    "from src.image_classifier.image_classifier import MNISTClassifier\n",
    "from src.utils import frechet_inception_distance\n",
    "from src.sampling import split_dirichlet"
   ],
   "id": "2487a85fbbe2c48b",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T15:08:34.235958Z",
     "start_time": "2024-05-03T15:08:34.102600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_data = torchvision.datasets.MNIST(root='../data/MNIST_train', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "testing_data = torchvision.datasets.MNIST(root='../data/MNIST_test', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "print(training_data)\n",
    "print(testing_data)\n",
    "\n",
    "input = training_data.data[:60000] / 255.0   # normalizing necessary to make pixels in [0, 1] range for FID\n",
    "labels = training_data.targets[:60000]"
   ],
   "id": "e88faf52309641be",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T15:08:06.913863Z",
     "start_time": "2024-05-03T15:07:30.766878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train VAE\n",
    "vae = VaeAutoencoder(dim_encoding=2)\n",
    "\n",
    "vae_classifier_model, vae_loss_li, kl_loss_li = vae.train_model(\n",
    "    training_data,\n",
    "    batch_size=100,\n",
    "    beta=1000,\n",
    "    epochs=20\n",
    ")"
   ],
   "id": "638840fffa01c1ff",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T15:10:37.878926Z",
     "start_time": "2024-05-03T15:10:37.781440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plot generated data\n",
    "image_tensor = vae.generate_data(n_samples=5)\n",
    "plot_image(image_tensor.cpu().detach().numpy())"
   ],
   "id": "d91353a176d11f1f",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T15:08:39.589733Z",
     "start_time": "2024-05-03T15:08:38.107077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# move tensors to cpu before converting to np array\n",
    "np_kl_loss_li = []\n",
    "\n",
    "for output in kl_loss_li:\n",
    "    if isinstance(output, Tensor):\n",
    "        np_kl_loss_li.append(output.cpu().detach().numpy())\n",
    "\n",
    "# plot results\n",
    "plot_vae_training_result(\n",
    "    input=input,\n",
    "    labels=labels,\n",
    "    vae_model=vae,\n",
    "    vae_loss_li=vae_loss_li,\n",
    "    kl_loss_li=np_kl_loss_li\n",
    ")"
   ],
   "id": "3728727191417337",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T15:09:29.689745Z",
     "start_time": "2024-05-03T15:08:44.982568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train classifier for performance evaluation\n",
    "\n",
    "classifier = MNISTClassifier(input_size=784, num_classes=10)\n",
    "classifier.train_model(training_data, batch_size=100, epochs=5)\n",
    "accuracy = classifier.test_model(testing_data)\n",
    "print(\"Test accuracy: \", accuracy)"
   ],
   "id": "45732cff7f69fc04",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T15:09:31.126562Z",
     "start_time": "2024-05-03T15:09:29.689745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = vae.generate_data(n_samples=10000)\n",
    "print(\"Number of images: \", x.shape[0])\n",
    "\n",
    "labels = classifier.generate_labels(x)\n",
    "print(\"Labels: \", labels.shape)"
   ],
   "id": "ac28c9b8927f8342",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T15:12:18.291501Z",
     "start_time": "2024-05-03T15:11:24.262947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate imbalanced data set for comparison of distribution of input vs distribution of generated images\n",
    "training_data = torchvision.datasets.MNIST(root='../data/MNIST_train', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "input = training_data.data[:60000]\n",
    "labels = training_data.targets[:60000]\n",
    "\n",
    "users_data = split_dirichlet(dataset=training_data, num_users=4, is_cfar=False, beta=0.5)\n",
    "\n",
    "total_input = []\n",
    "total_labels = []\n",
    "total_counts = []\n",
    "for user_idx in users_data:\n",
    "    images = []\n",
    "    outputs = []\n",
    "    counts = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    for data_idx in users_data[user_idx]:\n",
    "        image = input[int(data_idx)]\n",
    "        images.append(image)\n",
    "        label = labels[int(data_idx)]\n",
    "        outputs.append(label)\n",
    "        counts[label] +=1\n",
    "    total_input.append(images)\n",
    "    total_labels.append(outputs)\n",
    "    total_counts.append(counts)\n",
    "\n",
    "user_idx = 0\n",
    "sample_input = total_input[user_idx]\n",
    "sample_label = total_labels[user_idx]\n",
    "\n",
    "input_tensor = torch.stack(sample_input)\n",
    "label_tensor = torch.stack(sample_label)\n",
    "\n",
    "plot_image_label_two (input_tensor.cpu().detach().numpy(), label_tensor.cpu().detach().numpy())\n",
    "\n",
    "assert input_tensor.shape[0] == label_tensor.shape[0]\n",
    "\n",
    "training_data.data = input_tensor\n",
    "training_data.targets = label_tensor\n",
    "\n",
    "assert training_data.data.shape == input_tensor.shape\n",
    "assert training_data.targets.shape == label_tensor.shape\n",
    "\n",
    "\n",
    "# Train VAE on imbalanced dataset\n",
    "vae_imbalanced = VaeAutoencoder(dim_encoding=2)\n",
    "\n",
    "_, _, _ = vae_imbalanced.train_model(\n",
    "    training_data,\n",
    "    batch_size=50,\n",
    "    beta=1000,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "gen_image = vae_imbalanced.generate_data(n_samples=sum(total_counts[user_idx]))\n",
    "gen_output = classifier.generate_labels(gen_image)\n",
    "gen_counts = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "for tensor_label in gen_output:\n",
    "    gen_counts[tensor_label[0]]+=1\n",
    "\n",
    "# plot generated data\n",
    "plot_image_label_two(gen_image.cpu().detach().numpy(), gen_output.cpu().detach().numpy())\n",
    "\n",
    "print(\"Input counts: \", total_counts[user_idx])\n",
    "print(\"Generated counts: \", gen_counts)"
   ],
   "id": "8facfceca09d32d",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # compute FID score\n",
    "# syn_input = vae.generate_data(n_samples=500)\n",
    "# input = input[:500]\n",
    "# \n",
    "# input_rgb = input.view(-1, 1, 28, 28).repeat(1, 3, 1, 1)\n",
    "# syn_input_rgb = syn_input.view(-1, 1, 28, 28).repeat(1, 3, 1, 1)\n",
    "# \n",
    "# # compute FID score (worst: 131, best: 85)\n",
    "# # 0 score only possible if absolutely identical\n",
    "# fid_score = frechet_inception_distance(input_rgb, syn_input_rgb)\n",
    "# print(\"Frechet Inception Distance: \", fid_score)"
   ],
   "id": "c740a72805ac4eec",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
